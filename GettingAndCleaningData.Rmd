---
title: "Getting and Cleaning Data"
output: html_notebook
---

Setup libraries and enviroment 

```{r, echo = FALSE}

# Package for tidyverse 
library("tidyverse")
library("lubridate")
# Package for building tables in markdown and notebook 
library("knitr")
library("kableExtra") 
# Package for forecasting
library("fpp2")
# Packages for reading excel and html files and XML
library("openxlsx")
library("XML")
# Parkage for using data tables for very large data operations
library("data.table")
#Package for reading fixed width tables
library("utils")
# Packages for reading data through API's 
library("httr")
library("jsonlite")
# Package for performing inquires with SQL databases 
library("sqldf")
#Package for reading and writing to jpeg files
library("jpeg")

# Set proper working Dir
if (!getwd() == "C:/Users/paulr/Documents/R/GettingAndCleaningData") {setwd("./GettingAndCleaningData")}

# Check for data directory and if one is not present then make it
if (!file.exists("data")) {
  dir.create("data")
}
```


Week 1
  Question 1

```{r}

# File to retreve from the internet: https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv
# Download data using a URL into th data directory
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv"
download.file(fileUrl, destfile = "./data/AmericanConsumer")
dateDownloaded <- date()
dateDownloaded
list.files("./data")

# Put data into a data frame or data table if very large, then look at the data 
survey <- data.frame(read.csv("./data/AmericanConsumer", header = TRUE))
str(survey)
glimpse(survey)
head(survey)
tail(survey)


# Subset or filter data frame for getting anssers
nrow(survey[,37 > 1])
nrow(subset(survey, VAL == 24))
nrow(survey[which(survey$VAL == 24),])
nrow(filter(survey, VAL == 24))
```

  Question 2
```{r}
# Identify if feacher is tidy
# Per data dictonary FES is: Family type and employment status. 
# Answer is there being 2 observations concatenate in this feacher. 
survey$FES
```

  Question 3
```{r}
# Read excel file https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FDATA.gov_NGAP.xlsx into a variable names dat
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FDATA.gov_NGAP.xlsx"
download.file(fileUrl, destfile = "./data/gov_NGAP.xlsx")
dateDownloaded <- date()

# Put data into a data frame or data table if very large, then look at the data 
rowIndex <- 18:23
colIndex <- 7:15
dat <- read.xlsx("C:/Users/paulr/Documents/R/GettingAndCleaningData/data/gov_NGAP.xlsx", 
                 sheet = 1, cols = colIndex, rows = rowIndex)
sum(dat$Zip*dat$Ext,na.rm=T)
```

  Question 4
```{r}
# https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml
# Set proper working Dir
if (!getwd() == "C:/Users/paulr/Documents/R/GettingAndCleaningData") {setwd("./GettingAndCleaningData")}
getwd()

# Check for data directory and if one is not present then make it
if (!file.exists("data")) {
  dir.create("data")
}

# Get file 
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
download.file(fileUrl, destfile = "./data/Frestaurants.xml")
dateDownloaded <- date()
doc <- xmlTreeParse("./data/Frestaurants.xml", useInternal=TRUE)
rootNode <- xmlRoot(doc)
codes <- (xpathSApply(rootNode, "//zipcode", xmlValue))
names <- (xpathSApply(rootNode, "//name", xmlValue))
answer <- data.frame("names" = names, "zipcode" = codes)
glimpse(answer)
nrow(answer[codes == 21231,])
```

Question 5
```{r}
# download https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv store in DT
# get average of $pwgtp15
# Set proper working Dir
if (!getwd() == "C:/Users/paulr/Documents/R/GettingAndCleaningData") {setwd("./GettingAndCleaningData")}
getwd()

# Check for data directory and if one is not present then make it
if (!file.exists("data")) {
  dir.create("data")
}
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv"
download.file(fileUrl, destfile = "./data/Fss06pid.csv")
dateDownloaded <- date()
DT <- fread("./data/Fss06pid.csv")
start <- Sys.time()
rowMeans(DT)[DT$SEX==1]; rowMeans(DT)[DT$SEX==2]
finish <- Sys.time()
finish - start 

start <- Sys.time()
mean(DT$pwgtp15, by=DT$SEX)
finish <- Sys.time()
finish - start 

start <- Sys.time()
mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15)
finish <- Sys.time()
finish - start 

start <- Sys.time()
sapply(split(DT$pwgtp15, DT$SEX), mean)
finish <- Sys.time()
finish - start 

start <- Sys.time()
tapply(DT$pwgtp15, DT$SEX, mean)
finish <- Sys.time()
finish - start 

start <- Sys.time()
DT[,mean(pwgtp15), by=SEX]
finish <- Sys.time()
finish - start 



# Week 2
# Question 1 
# https://github.com/paulrode/httr/blob/master/demo/oauth2-github.r location of demo 
# which i forked into my Git Repo listing for API access and question 1
# https://github.com/settings/applications/1323008 my registered API app
# Client ID:  e61cdf7b1bfa1692a861
# Client Secret: 51d4844467e47d72dc8e3dc3dea3a05ded011618

#Set up the app
myapp = oauth_app("github", 
                  key="e61cdf7b1bfa1692a861", secret= "51d4844467e47d72dc8e3dc3dea3a05ded011618")
sig = sign_oauth1.0(myapp)
reg <- GET("https://api.github.com/users/jtleek/repos", sig)

#Use the app to get a json page from which to bring into a data frame 
json1 = content(reg)
json2 = jsonlite::fromJSON(toJSON(json1))
json2[ , c(3 == "datasharing",47)]
json2 %>% filter(name == "datasharing") %>% select(name, created_at)
```

Question 2 
 The sqldf package allows for execution of SQL commands on R data 
 frames. We will use the sqldf package to practice the queries we 
 might send with the dbSendQuery command in RMySQL.
 Download Download the American Community Survey data and load it 
 into an R object called acs.            https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv

```{r}
# Set proper working Dir
if (!getwd() == "C:/Users/paulr/Documents/R/GettingAndCleaningData") {setwd("./GettingAndCleaningData")}
getwd()
# Check for data directory and if one is not present then make it
if (!file.exists("data")) {
  dir.create("data")}
# Get file
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv"
download.file(fileUrl, destfile = "./data/Fss06pid.csv")
dateDownloaded <- date()
acs <- read.csv("./data/Fss06pid.csv")
glimpse(acs)
str(sqldf("select pwgtp1 from acs where AGEP<50"))

# Question 3
# Which of the following commands will select only the data for the probability weights pwgtp1 with 
# ages less than 50?
unique(acs$AGEP)
glimpse(unique(acs$AGEP))
sqldf("select AGEP where unique from acs") #no
sqldf("select unique AGEP from ACS") #no
sqldf("select distinct AGEP from acs") # answer
sqldf("select distinct pwgtp1 from acs") #no


# Question 4 Webscraping 
# Which of the following commands will select only the data for 
# the probability weights pwgtp1 with ages less than 50?
# http://biostat.jhsph.edu/~jleek/contact.html

# Set proper working Dir
if (!getwd() == "C:/Users/paulr/Documents/R/GettingAndCleaningData") {setwd("./GettingAndCleaningData")}
getwd()
# Check for data directory and if one is not present then make it
if (!file.exists("data")) {
  dir.create("data")}
# Get Page
con = url("http://biostat.jhsph.edu/~jleek/contact.html")
htmlCode = readLines(con)
close(con)
htmlCode
nchar(htmlCode[c(10, 20, 30, 100)])


#Question 5 
# Read this data set into R and report the sum of the numbers in 
# the fourth of the nine columns.
# https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for
# Original source of the data: http://www.cpc.ncep.noaa.gov/data/indices/wksst8110.for
# (Hint this is a fixed width file format)

# Set proper working Dir
if (!getwd() == "C:/Users/paulr/Documents/R/GettingAndCleaningData") {setwd("./GettingAndCleaningData")}
getwd()
# Check for data directory and if one is not present then make it
if (!file.exists("data")) {
  dir.create("data")}
# Get Page
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for"
download.file(fileUrl, destfile = "./data/Fwksst8110.for")
dateDownloaded <- date()
#Use the read.table() funciton
# con <- read.table("./data/Fwksst8110.for", skip = 4, header = TRUE)
con <- read.fwf("./data/Fwksst8110.for", widths = c(-1, 9, -5, 4,-1,3, -5, 4,-1,3, -5, 4,-1,3, -5, 4,-1,3), col.names = c("week", "col1", "col2", "col3", "col4", "col5", "col6", "col7","col8"), strip.white = TRUE, skip = 4)
con
sum(as.numeric(con$col3))

```

Week 3 Subsetting and sorting 

Question #1 

The American Community Survey distributes downloadable data about United States communities. Download the 2006 microdata survey about housing for the state of Idaho using download.file() from here:

https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv

and load the data into R. The code book, describing the variable names is here:

https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FPUMSDataDict06.pdf

Create a logical vector that identifies the households on greater than 10 acres who sold more than $10,000 worth of agriculture products. Assign that logical vector to the variable agricultureLogical. Apply the which() function like this to identify the rows of the data frame where the logical vector is TRUE.

which(agricultureLogical)

What are the first 3 values that result?

```{r}

# Download data using a URL into th data directory
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv"
download.file(fileUrl, destfile = "./data/AmericanConsumer")
dateDownloaded <- date()
dateDownloaded
list.files("./data")

# Put data into a data frame or data table if very large, then look at the data 
survey <- data.frame(read.csv("./data/AmericanConsumer", header = TRUE))

# Make the logical vector using conditions
agricultureLogical <- (survey$ACR == 3 & survey$AGS == 6)
# which() returns the indicies of the condition  
which(agricultureLogical, TRUE) 

```

Question #2

Using the jpeg package read in the following picture of your instructor into R

https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg

Use the parameter native=TRUE. What are the 30th and 80th quantiles of the resulting data? (some Linux systems may produce an answer 638 different for the 30th quantile)

```{r}

# Download data using a URL into th data directory
# Note down.load did not work for this problem. It has an issue with jpeg photos. 
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg"
download.file(fileUrl, destfile = "./data/picture.jpg")
dateDownloaded <- date()
list.files("./data")

# Read jpeg into R and execute the quantile command
picture.r <- readJPEG("./data/picture.jpg", native = TRUE) 
glimpse(picture.r)
head(picture.r)
tail(picture.r)

quantile(picture.r, probs = c(0, .3, .5, .8, 1)   ,na.rm = TRUE)


```


Question #3

Load the Gross Domestic Product data for the 190 ranked countries in this data set:

https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv

Load the educational data from this data set:

https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv

Match the data based on the country shortcode. How many of the IDs match? Sort the data frame in descending order by GDP rank (so United States is last). What is the 13th country in the resulting data frame?

Original data sources:

http://data.worldbank.org/data-catalog/GDP-ranking-table

http://data.worldbank.org/data-catalog/ed-stats


```{r}

# Download data using a URL into th data directory
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
download.file(fileUrl, destfile = "./data/gpd")
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv"
download.file(fileUrl, destfile = "./data/education")
dateDownloaded <- date()
dateDownloaded
list.files("./data")

# Put data into a data frame or data table if very large, then look at the data 
gpd.r <- data.frame(read.csv("./data/gpd", skip = 4, nrows = 190L))
education.r <- data.frame(read.csv("./data/education", header = TRUE))
colnames(gpd.r)[1:2] = c("CountryCode", "Gross.domestic.product.2012")
gpd.r %>% arrange(desc(Gross.domestic.product.2012))
#  answer
length( match(gpd.r$CountryCode, education.r$CountryCode))
ans <- merge(gpd.r, education.r)
arrange(ans, desc(Gross.domestic.product.2012  )) -> ans
ans[13,]

```


Question 4

What is the average GDP ranking for the "High income: OECD" and "High income: nonOECD" group?

```{r}

# Download data using a URL into th data directory
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
download.file(fileUrl, destfile = "./data/gpd")
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv"
download.file(fileUrl, destfile = "./data/education")
dateDownloaded <- date()
dateDownloaded
list.files("./data")

# Put data into a data frame or data table if very large, then look at the data 
gpd.r <- data.frame(read.csv("./data/gpd", skip = 4, nrows = 190L))
education.r <- data.frame(read.csv("./data/education", header = TRUE))
colnames(gpd.r)[1:2] = c("CountryCode", "Gross.domestic.product.2012")


glimpse(gpd.r)
head(gpd.r, 10)
glimpse(education.r)
head(education.r, 10)

```



Question 5 

Cut the GDP ranking into 5 separate quantile groups. Make a table versus Income.Group. How many countries

are Lower middle income but among the 38 nations with highest GDP?

```{r}

# Download data using a URL into th data directory

fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
download.file(fileUrl, destfile = "./data/gpd")
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv"
download.file(fileUrl, destfile = "./data/education")
dateDownloaded <- date()
dateDownloaded
list.files("./data")

# Put data into a data frame or data table if very large, then look at the data 
gpd.r <- data.frame(read.csv("./data/gpd", skip = 4, nrows = 190L))
education.r <- data.frame(read.csv("./data/education", header = TRUE))
colnames(gpd.r)[1:2] = c("CountryCode", "Gross.domestic.product.2012")
gpd_edu <- merge(gpd.r, education.r)
gpd_edu %>% arrange(desc(Gross.domestic.product.2012)) -> gpd_edu
quantile(gpd_edu$Gross.domestic.product.2012 , probs =  c( .2, .4, .6, .8, 1), na.rm = TRUE)



gpd_edu %>% group_by(Income.Group) %>% summarize(Income.Group, by())

sum(gpd_edu$Gross.domestic.product.2012)
view(gpd_edu)
glimpse(education.r)
str(education.r)

data.frame(levels(education.r$Income.Group))

```
